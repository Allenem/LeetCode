{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Simple RNN\n",
    "\n",
    "Write a Python function that implements a simple Recurrent Neural Network (RNN) cell. The function should process a sequence of input vectors and produce the final hidden state. Use the tanh activation function for the hidden state updates. The function should take as inputs the sequence of input vectors, the initial hidden state, the weight matrices for input-to-hidden and hidden-to-hidden connections, and the bias vector. The function should return the final hidden state after processing the entire sequence, rounded to four decimal places.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "    input_sequence = [[1.0], [2.0], [3.0]]\n",
    "    initial_hidden_state = [0.0]\n",
    "    Wx = [[0.5]]  # Input to hidden weights\n",
    "    Wh = [[0.8]]  # Hidden to hidden weights\n",
    "    b = [0.0]     # Bias\n",
    "    output: final_hidden_state = [0.9993]\n",
    "    reasoning: The RNN processes each input in the sequence, updating the hidden state at each step using the tanh activation function.\n",
    "```\n",
    "\n",
    "## Understanding Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Recurrent Neural Networks are a class of neural networks designed to handle sequential data by maintaining a hidden state that captures information from previous inputs.\n",
    "\n",
    "## Mathematical Formulation\n",
    "\n",
    "For each time step $t$, the RNN updates its hidden state $h_t$ using the current input $x_t$ and the previous hidden state $h_{t-1}$:\n",
    "\n",
    "$h_t = \\tanh(W_{x}x_t + W_{h}h_{t-1} + b)$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $W_{x}$ is the weight matrix for the input-to-hidden connections.\n",
    "- $W_{h}$ is the weight matrix for the hidden-to-hidden connections.\n",
    "- $b$ is the bias vector.\n",
    "- $\\tanh$ is the hyperbolic tangent activation function applied element-wise.\n",
    "\n",
    "## Implementation Steps\n",
    "\n",
    "Initialization: Start with the initial hidden state $h_0$.\n",
    "\n",
    "Sequence Processing: For each input $x_t$ in the sequence:\n",
    "\n",
    "Compute $h_t = \\tanh(W_{x}x_t + W_{h}h_{t-1} + b)$.\n",
    "\n",
    "Final Output: After processing all inputs, the final hidden state $h_T$ (where $T$ is the length of the sequence) contains information from the entire sequence.\n",
    "\n",
    "## Example Calculation\n",
    "\n",
    "Given:\n",
    "\n",
    "Inputs: $x_1 = 1.0, x_2 = 2.0, x_3 = 3.0$\n",
    "\n",
    "Initial hidden state: $h_0 = 0.0$\n",
    "\n",
    "Weights: $W_{x} = 0.5, W_{h} = 0.8$\n",
    "\n",
    "Bias: $b = 0.0$\n",
    "\n",
    "Compute:\n",
    "\n",
    "First time step ($t = 1$):\n",
    "\n",
    "$h_1 = \\tanh(0.5 \\times 1.0 + 0.8 \\times 0.0 + 0.0) = \\tanh(0.5) \\approx 0.4621$\n",
    "\n",
    "Second time step ($t = 2$):\n",
    "\n",
    "$h_2 = \\tanh(0.5 \\times 2.0 + 0.8 \\times 0.4621 + 0.0) = \\tanh(1.4621) \\approx 0.8915$\n",
    "\n",
    "Third time step ($t = 3$):\n",
    "\n",
    "$h_3 = \\tanh(0.5 \\times 3.0 + 0.8 \\times 0.8915 + 0.0) = \\tanh(2.2452) \\approx 0.9750$\n",
    "\n",
    "The final hidden state $h_3$ is approximately 0.9750.\n",
    "\n",
    "## Applications\n",
    "\n",
    "RNNs are widely used in natural language processing, time-series prediction, and any task involving sequential data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rnn_forward(input_sequence, initial_hidden_state, Wx, Wh, b):\n",
    "    h = np.array(initial_hidden_state)\n",
    "    Wx = np.array(Wx)\n",
    "    Wh = np.array(Wh)\n",
    "    b = np.array(b)\n",
    "    for x in input_sequence:\n",
    "        x = np.array(x)\n",
    "        h = np.tanh(np.dot(Wx, x) + np.dot(Wh, h) + b)\n",
    "    final_hidden_state = np.round(h, 4)\n",
    "    return final_hidden_state.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1: Accepted\n",
      "Input:\n",
      "print(rnn_forward([[1.0], [2.0], [3.0]], [0.0], [[0.5]], [[0.8]], [0.0]))\n",
      "\n",
      "Output:\n",
      "[0.9759]\n",
      "\n",
      "Expected:\n",
      "[0.9759]\n",
      "\n",
      "\n",
      "Test Case 2: Accepted\n",
      "Input:\n",
      "print(rnn_forward([[0.5], [0.1], [-0.2]], [0.0], [[1.0]], [[0.5]], [0.1]))\n",
      "\n",
      "Output:\n",
      "[0.118]\n",
      "\n",
      "Expected:\n",
      "[0.118]\n",
      "\n",
      "\n",
      "Test Case 3: Accepted\n",
      "Input:\n",
      "print(rnn_forward(\n",
      "    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\n",
      "    [0.0, 0.0],\n",
      "    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\n",
      "    [[0.7, 0.8], [0.9, 1.0]],\n",
      "    [0.1, 0.2]\n",
      "))\n",
      "\n",
      "Output:\n",
      "[0.7474, 0.9302]\n",
      "\n",
      "Expected:\n",
      "[0.7474, 0.9302]\n"
     ]
    }
   ],
   "source": [
    "Output = rnn_forward([[1.0], [2.0], [3.0]], [0.0], [[0.5]], [[0.8]], [0.0])\n",
    "print('Test Case 1: Accepted') if Output == [0.9759] else print('Test Case 1: Failed')\n",
    "print('Input:')\n",
    "print('print(rnn_forward([[1.0], [2.0], [3.0]], [0.0], [[0.5]], [[0.8]], [0.0]))')\n",
    "print()\n",
    "print('Output:')\n",
    "print(Output)\n",
    "print()\n",
    "print('Expected:')\n",
    "print('[0.9759]')\n",
    "print()\n",
    "print()\n",
    "\n",
    "Output = rnn_forward([[0.5], [0.1], [-0.2]], [0.0], [[1.0]], [[0.5]], [0.1])\n",
    "print('Test Case 2: Accepted') if Output == [0.118] else print('Test Case 2: Failed')\n",
    "print('Input:')\n",
    "print('print(rnn_forward([[0.5], [0.1], [-0.2]], [0.0], [[1.0]], [[0.5]], [0.1]))')\n",
    "print()\n",
    "print('Output:')\n",
    "print(Output)\n",
    "print()\n",
    "print('Expected:')\n",
    "print('[0.118]')\n",
    "print()\n",
    "print()\n",
    "\n",
    "Output = rnn_forward(\n",
    "    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\n",
    "    [0.0, 0.0],\n",
    "    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\n",
    "    [[0.7, 0.8], [0.9, 1.0]],\n",
    "    [0.1, 0.2]\n",
    ")\n",
    "print('Test Case 3: Accepted') if Output == [0.7474, 0.9302] else print('Test Case 3: Failed')\n",
    "print('Input:')\n",
    "print('print(rnn_forward(\\n    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\\n    [0.0, 0.0],\\n    [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]],\\n    [[0.7, 0.8], [0.9, 1.0]],\\n    [0.1, 0.2]\\n))')\n",
    "print()\n",
    "print('Output:')\n",
    "print(Output)\n",
    "print()\n",
    "print('Expected:')\n",
    "print('[0.7474, 0.9302]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
