{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Using Normal Equation (easy)\n",
    "\n",
    "Write a Python function that performs linear regression using the normal equation. The function should take a matrix X (features) and a vector y (target) as input, and return the coefficients of the linear regression model. Round your answer to four decimal places, -0.0 is a valid result for rounding a very small number.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "        input: X = [[1, 1], [1, 2], [1, 3]], y = [1, 2, 3]\n",
    "        output: [0.0, 1.0]\n",
    "        reasoning: The linear model is y = 0.0 + 1.0*x, perfectly fitting the input data.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Using the Normal Equation\n",
    "\n",
    "Linear regression aims to model the relationship between a scalar dependent variable $y$ and one or more explanatory variables (or independent variables) $X$. The normal equation provides an analytical solution to finding the coefficients $\\theta$ that minimize the cost function for linear regression. Given a matrix $X$ (with each row representing a training example and each column a feature) and a vector $y$ (representing the target values), the normal equation is:\n",
    "\n",
    "$$\\theta = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "Where:\n",
    "- $X^T$ is the transpose of the matrix $X$,\n",
    "- $(X^T X)^{-1}$ is the inverse of the matrix $X^T X$,\n",
    "- $y$ is the vector of target values.\n",
    "\n",
    "**Things to note**: This method does not require any feature scaling, and there's no need to choose a learning rate. However, computing the inverse of $X^T X$ can be computationally expensive if the number of features is very large.\n",
    "\n",
    "## Practical Implementation\n",
    "\n",
    "A practical implementation involves augmenting $X$ with a column of ones to account for the intercept term and then applying the normal equation directly to compute $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear_regression_normal_equation(X: list[list[float]], y: list[float]) -> list[float]:\n",
    "    # Your code here, make sure to round\n",
    "    X = np.array(X)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "    XT = X.T\n",
    "    theta = np.linalg.inv(XT.dot(X)).dot(XT).dot(y)\n",
    "    theta = np.round(theta, 4).flatten().tolist()\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1: Accepted\n",
      "Input:\n",
      "print(linear_regression_normal_equation([[1, 1], [1, 2], [1, 3]], [1, 2, 3]))\n",
      "\n",
      "Output:\n",
      "[0.0, 1.0]\n",
      "\n",
      "Expected:\n",
      "[-0.0, 1.0]\n",
      "\n",
      "\n",
      "Test Case 2: Accepted\n",
      "Input:\n",
      "print(linear_regression_normal_equation([[1, 3, 4], [1, 2, 5], [1, 3, 2]], [1, 2, 1]))\n",
      "\n",
      "Output:\n",
      "[4.0, -1.0, -0.0]\n",
      "\n",
      "Expected:\n",
      "[4.0, -1.0, -0.0]\n"
     ]
    }
   ],
   "source": [
    "print('Test Case 1: Accepted') if linear_regression_normal_equation([[1, 1], [1, 2], [1, 3]], [1, 2, 3]) == [-0.0, 1.0] else print('Test Case 1: Rejected')\n",
    "print('Input:')\n",
    "print('print(linear_regression_normal_equation([[1, 1], [1, 2], [1, 3]], [1, 2, 3]))')\n",
    "print()\n",
    "print('Output:')\n",
    "print(linear_regression_normal_equation([[1, 1], [1, 2], [1, 3]], [1, 2, 3]))\n",
    "print()\n",
    "print('Expected:')\n",
    "print('[-0.0, 1.0]')\n",
    "print()\n",
    "print()\n",
    "\n",
    "print('Test Case 2: Accepted') if linear_regression_normal_equation([[1, 3, 4], [1, 2, 5], [1, 3, 2]], [1, 2, 1]) == [4.0, -1.0, -0.0] else print('Test Case 2: Rejected')\n",
    "print('Input:')\n",
    "print('print(linear_regression_normal_equation([[1, 3, 4], [1, 2, 5], [1, 3, 2]], [1, 2, 1]))')\n",
    "print()\n",
    "print('Output:')\n",
    "print(linear_regression_normal_equation([[1, 3, 4], [1, 2, 5], [1, 3, 2]], [1, 2, 1]))\n",
    "print()\n",
    "print('Expected:')\n",
    "print('[4.0, -1.0, -0.0]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
