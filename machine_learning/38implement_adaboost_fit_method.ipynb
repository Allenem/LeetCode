{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement AdaBoost Fit Method\n",
    "\n",
    "Write a Python function `adaboost_fit` that implements the fit method for an AdaBoost classifier. The function should take in a 2D numpy array `X` of shape `(n_samples, n_features)` representing the dataset, a 1D numpy array `y` of shape `(n_samples,)` representing the labels, and an integer `n_clf` representing the number of classifiers. The function should initialize sample weights, find the best thresholds for each feature, calculate the error, update weights, and return a list of classifiers with their parameters.\n",
    "\n",
    "Example:\n",
    "```py\n",
    "    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "    y = np.array([1, 1, -1, -1])\n",
    "    n_clf = 3\n",
    "\n",
    "    clfs = adaboost_fit(X, y, n_clf)\n",
    "    print(clfs)\n",
    "    # Output (example format, actual values may vary):\n",
    "    # [{'polarity': 1, 'threshold': 2, 'feature_index': 0, 'alpha': 0.5},\n",
    "    #  {'polarity': -1, 'threshold': 3, 'feature_index': 1, 'alpha': 0.3},\n",
    "    #  {'polarity': 1, 'threshold': 4, 'feature_index': 0, 'alpha': 0.2}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding AdaBoost\n",
    "\n",
    "AdaBoost, short for Adaptive Boosting, is an ensemble learning method that combines multiple weak classifiers to create a strong classifier. The basic idea is to fit a sequence of weak learners on weighted versions of the data.\n",
    "\n",
    "Here's how to implement the fit method for an AdaBoost classifier:\n",
    "\n",
    "- **Initialize Weights**: Start by initializing the sample weights uniformly:\n",
    "\n",
    "    $w_i = \\frac{1}{N}$, where $w_i$ is the weight of the $i$-th sample and $N$ is the total number of samples.\n",
    " \n",
    "- **Iterate Through Classifiers**: For each classifier, determine the best threshold for each feature to minimize the error.\n",
    "\n",
    "- **Calculate Error and Flip Polarity**: If the error is greater than 0.5, flip the polarity:\n",
    "    \n",
    "    $error = \\sum_{i=1}^{N} w_i \\cdot \\mathbb{1}(y_i \\neq h(x_i))$, where $\\mathbb{1}$ is the indicator function, $y_i$ is the true label, and $h(x_i)$ is the predicted label.\n",
    "\n",
    "    If $error > 0.5$, set $error = 1 - error$ and flip the polarity.\n",
    "\n",
    "- **Calculate Alpha**: Compute the weight (alpha) of the classifier based on its error rate:\n",
    "    \n",
    "    $\\alpha = \\frac{1}{2} \\ln\\left(\\frac{1 - error}{error + 1e-10}\\right)$\n",
    " \n",
    "- **Update Weights**: Adjust the sample weights based on the classifier's performance and normalize them:\n",
    "\n",
    "    $w_i = w_i \\cdot \\exp(-\\alpha \\cdot y_i \\cdot h(x_i))$\n",
    "    \n",
    "    $w_i = \\frac{w_i}{\\sum_{i=1}^{N} w_i}$\n",
    " \n",
    "- **Save Classifier**: Store the classifier with its parameters.\n",
    "\n",
    "This method helps in focusing more on the misclassified samples in subsequent rounds, thereby improving the overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def adaboost_fit(X, y, n_clf):\n",
    "    n_samples, n_features = np.shape(X)\n",
    "\t# 1. Initialize Weights\n",
    "    w = np.full(n_samples, (1 / n_samples))\n",
    "    clfs = []\n",
    "    \n",
    "\t# 2. Iterate Through Classifiers: For each classifier, \n",
    "\t# determine the best threshold for each feature to minimize the error.\n",
    "    for _ in range(n_clf):\n",
    "        clf = {}\n",
    "        min_error = float('inf')\n",
    "        \n",
    "        for feature_i in range(n_features):\n",
    "            feature_values = np.expand_dims(X[:, feature_i], axis=1)\n",
    "            unique_values = np.unique(feature_values)\n",
    "            \n",
    "            for threshold in unique_values:\n",
    "                p = 1\n",
    "                prediction = np.ones(np.shape(y))\n",
    "                prediction[X[:, feature_i] < threshold] = -1\n",
    "\t\t\t\t\n",
    "\t\t\t\t# 3. Calculate Error and Flip Polarity: If the error is greater than 0.5, flip the polarity\n",
    "                error = sum(w[y != prediction])\n",
    "                if error > 0.5:\n",
    "                    error = 1 - error\n",
    "                    p = -1\n",
    "                \n",
    "                if error < min_error:\n",
    "                    clf['polarity'] = p\n",
    "                    clf['threshold'] = threshold\n",
    "                    clf['feature_index'] = feature_i\n",
    "                    min_error = error\n",
    "        \n",
    "\t\t# 4. Calculate Alpha: Compute the weight (alpha) of the 'classifier' based on its error rate\n",
    "        clf['alpha'] = 0.5 * math.log((1.0 - min_error) / (min_error + 1e-10))\n",
    "\t\t\n",
    "\t\t# 5. Update Weights: Adjust the 'sample' weights based on the classifier's performance and normalize them\n",
    "        predictions = np.ones(np.shape(y))\n",
    "        negative_idx = (clf['polarity'] * X[:, clf['feature_index']] < clf['polarity'] * clf['threshold'])\n",
    "        predictions[negative_idx] = -1\n",
    "\t\t\n",
    "        w *= np.exp(-clf['alpha'] * y * predictions)\n",
    "        w /= np.sum(w)\n",
    "        clfs.append(clf)\n",
    "\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "y = np.array([1, 1, -1, -1])\n",
      "n_clf = 3\n",
      "clfs = adaboost_fit(X, y, n_clf)\n",
      "print(clfs)\n",
      "\n",
      "Output:\n",
      "[{'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512925464970229}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512924909859024}, {'polarity': -1, 'threshold': 1, 'feature_index': 0, 'alpha': 11.512925464970229}]\n",
      "\n",
      "Expected:\n",
      "[{'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512925464970229}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512924909859024}, {'polarity': -1, 'threshold': 1, 'feature_index': 0, 'alpha': 11.512925464970229}]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "y = np.array([1, 1, -1, -1])\n",
    "n_clf = 3\n",
    "clfs = adaboost_fit(X, y, n_clf)\n",
    "\n",
    "print('Input:\\n\\\n",
    "y = np.array([1, 1, -1, -1])\\n\\\n",
    "n_clf = 3\\n\\\n",
    "clfs = adaboost_fit(X, y, n_clf)\\n\\\n",
    "print(clfs)')\n",
    "print()\n",
    "print('Output:')\n",
    "print(clfs)\n",
    "print()\n",
    "print('Expected:')\n",
    "print([{'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512925464970229}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512924909859024}, {'polarity': -1, 'threshold': 1, 'feature_index': 0, 'alpha': 11.512925464970229}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "X = np.array([[8, 7], [3, 4], [5, 9], [4, 0], [1, 0], [0, 7], [3, 8], [4, 2], [6, 8], [0, 2]])\n",
      "y = np.array([1, -1, 1, -1, 1, -1, -1, -1, 1, 1])\n",
      "n_clf = 2\n",
      "clfs = adaboost_fit(X, y, n_clf)\n",
      "print(clfs)\n",
      "\n",
      "Output:\n",
      "[{'polarity': 1, 'threshold': 5, 'feature_index': 0, 'alpha': 0.6931471803099453}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 0.5493061439673882}]\n",
      "\n",
      "Expected:\n",
      "[{'polarity': 1, 'threshold': 5, 'feature_index': 0, 'alpha': 0.6931471803099453}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 0.5493061439673882}]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[8, 7], [3, 4], [5, 9], [4, 0], [1, 0], [0, 7], [3, 8], [4, 2], [6, 8], [0, 2]])\n",
    "y = np.array([1, -1, 1, -1, 1, -1, -1, -1, 1, 1])\n",
    "n_clf = 2\n",
    "clfs = adaboost_fit(X, y, n_clf)\n",
    "\n",
    "print('Input:\\n\\\n",
    "X = np.array([[8, 7], [3, 4], [5, 9], [4, 0], [1, 0], [0, 7], [3, 8], [4, 2], [6, 8], [0, 2]])\\n\\\n",
    "y = np.array([1, -1, 1, -1, 1, -1, -1, -1, 1, 1])\\n\\\n",
    "n_clf = 2\\n\\\n",
    "clfs = adaboost_fit(X, y, n_clf)\\n\\\n",
    "print(clfs)')\n",
    "print()\n",
    "print('Output:')\n",
    "print(clfs)\n",
    "print()\n",
    "print('Expected:')\n",
    "print([{'polarity': 1, 'threshold': 5, 'feature_index': 0, 'alpha': 0.6931471803099453}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 0.5493061439673882}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
